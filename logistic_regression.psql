
create or replace function diff(in a float, in b float)
    returns float
    language plpgsql stable
as $$
begin
    return a - b;
end;
$$;
create or replace function dot(in x float[][], in y float[])
returns float[]
language plpgsql stable
as $$
    declare
        output float[];
        i int;
        j int;
        aggregate float;
    begin
        for i in 1..array_length(x, 1) loop
            aggregate = 0;
            for j in 1..array_length(x, 2) loop
                aggregate := aggregate + x[i][j] * y[j];
                end loop;
            output := array_append(output, aggregate);
        end loop;

        return output;
    end;
    $$;

create or replace function t(in x float[][])
returns float[][]
language plpgsql stable
as $$
    declare
        output float[][];

        i int;
        j int;

        i_len int; -- features in input
        j_len int; -- elems in input
    begin

        i_len = array_length(x, 1);
        j_len = array_length(x, 2);
        output := array_fill(NULL::float, ARRAY[j_len, i_len]);

        for j in 1..j_len loop
            for i in 1..i_len loop
                output[j][i] = x[i][j];
            end loop;
        end loop;

        return output;
    end;
$$;



create or replace function sigmoid(in x float)
    returns float
    language plpgsql stable
as $$
    begin
        return 1 / (1 + power(2.718281828459045, -x));

    end;
    $$;


drop function bin_log_reg;
create or replace function bin_log_reg (in X float[][], in y float[])
    returns float[]
    language plpgsql stable
as $$
declare
    bias float := 0;
    learn_rate float := 0.001;

    n_samples integer;
    n_features integer;

    weights float[];
    pred float[];
    dz float[];
    dw float[];
    db float;
begin
    n_samples = array_length(X, 1);
    n_features = array_length(X, 2);
    weights = array_fill(0.0, ARRAY[n_features]);

    for i in 1..1750 loop
        pred := ARRAY(select sigmoid(x_0::float) from unnest(dot(x, weights)) as x_0);
        dz:= ARRAY(select a-b from (select a, row_number() over() as row_num from unnest(pred) as a) t1
                join lateral (
                select b, row_number() over() as row_num from unnest(y) as b) t2
                on t1.row_num = t2.row_num
                where t1.row_num = t2.row_num);
        dw := ARRAY(select (1.0 / n_samples) * elem from unnest(dot(t(x), dz)) as elem);
        db := (1 / n_samples) * (select (sum(preds) - sum(ys)) from unnest(pred) as preds, unnest(y) as ys);

        weights := ARRAY(select weight - learn_rate * dws from (select weight, row_number() over() as row_num from unnest(weights) as weight) tb1
            join (select dws, row_number() over() as row_num from unnest(dw) as dws) tb2
            on tb1.row_num = tb2.row_num
            where tb1.row_num = tb2.row_num);
        bias := bias - learn_rate * db;
    end loop;

    return weights;
end
$$;
select bin_log_reg(ARRAY[ARRAY[1.0, 1.0], ARRAY[0.0, 1.0]]::float[][], ARRAY[1.0, 0.0]::float[]);